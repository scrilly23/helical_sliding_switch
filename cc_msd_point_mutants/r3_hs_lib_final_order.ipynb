{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "1de79093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "e0bd7290",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = '/Users/stephaniecrilly/Library/CloudStorage/Box-Box/kortemmelab/home/scrilly/helix_sliding/20260128_r3_hs_lib'\n",
    "\n",
    "r3_all_ordered_seqs_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "c10956c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#control seq functions\n",
    "\n",
    "####Heptad a and d to Ala####\n",
    "def heptad_to_upper(input_string, split_char = 'r '):\n",
    "    split_1 = input_string.split(split_char)[0]\n",
    "    split_2 = input_string.split(split_char)[1]\n",
    "    split_2 = split_2.upper()\n",
    "    \n",
    "    new_string = split_1+split_char+split_2\n",
    "\n",
    "    return new_string\n",
    "\n",
    "\n",
    "def heptad_a_d_to_ala(reg_string, seq_string):\n",
    "\n",
    "    og_seq = re.split(r'\\s+', seq_string)[1]\n",
    "    \n",
    "    for index, char in enumerate(reg_string):\n",
    "        if char.isupper():\n",
    "            if char in ['A', 'D']:\n",
    "                seq_string = seq_string[:index] + 'A' + seq_string[index+1:]\n",
    "            else:\n",
    "                continue\n",
    "    \n",
    "    new_seq = re.split(r'\\s+', seq_string)[1]\n",
    "\n",
    "    return og_seq, new_seq\n",
    "\n",
    "\n",
    "def a_d_to_ala(input_df, state='ssd', mode='old'):\n",
    "\n",
    "    new_seqs_dict = {}\n",
    "\n",
    "    if state == 'ssd':\n",
    "        h1_reg_colname = 'h1_reg'\n",
    "        h2_reg_colname = 'h2_reg'\n",
    "\n",
    "        h1_seq_colname = 'h1_seq'\n",
    "        h2_seq_colname = 'h2_seq'\n",
    "    elif state == 'msd':\n",
    "        h1_reg_colname = 'h1_reg_min2'\n",
    "        h2_reg_colname = 'h2_reg_min2'\n",
    "\n",
    "        h1_seq_colname = 'h1_seq_min2'\n",
    "        h2_seq_colname = 'h2_seq_min2'\n",
    "\n",
    "    for index, row in input_df.iterrows():\n",
    "\n",
    "        h1_reg = row[h1_reg_colname]\n",
    "        new_h1_reg = heptad_to_upper(h1_reg)\n",
    "\n",
    "        h1_seq = row[h1_seq_colname]\n",
    "\n",
    "        h1_og, h1_new = heptad_a_d_to_ala(new_h1_reg, h1_seq)\n",
    "\n",
    "        h2_reg = row[h2_reg_colname]\n",
    "        new_h2_reg = heptad_to_upper(h2_reg)\n",
    "\n",
    "        h2_seq = row[h2_seq_colname]\n",
    "\n",
    "        h2_og, h2_new = heptad_a_d_to_ala(new_h2_reg, h2_seq)\n",
    "\n",
    "        #replace with ala seq in sequence\n",
    "        if mode == 'old':\n",
    "            sequence = row['final_sequence_for_ad']\n",
    "            new_sequence = sequence.replace(h1_og, h1_new)\n",
    "            new_sequence = new_sequence.replace(h2_og, h2_new)\n",
    "        if mode == 'new':\n",
    "            sequence = row['final_sequence_for_ad']\n",
    "            #get index of alfa tag\n",
    "            alfa_index = sequence.index('SRLEEELRRRLTE')\n",
    "            conserved_region = sequence[alfa_index-3:]\n",
    "\n",
    "            new_sequence = sequence.replace(h1_og, h1_new)\n",
    "            new_sequence = new_sequence.replace(h2_og, h2_new)\n",
    "            new_sequence = new_sequence[:alfa_index-3] + conserved_region\n",
    "\n",
    "        new_seqs_dict[sequence] = new_sequence\n",
    "\n",
    "    new_df = input_df.copy()\n",
    "    new_df['a_d_to_ala_sequence'] = new_df['final_sequence_for_ad'].map(new_seqs_dict)\n",
    "\n",
    "    return new_df\n",
    "\n",
    "####\n",
    "\n",
    "####SCRAMBLE CONTROLS####\n",
    "def full_scrambler(sequence_list):\n",
    "    '''function for full scrambles use random.sample\n",
    "    Takes a list of original design sequences\n",
    "    Outputs a dictionary with original seq and fully scrambled seq as key:value pair'''\n",
    "\n",
    "    full_scramble_dict = {}\n",
    "    for seq in sequence_list:\n",
    "        residues = list(seq)\n",
    "        sc_residues = random.sample(residues, k=len(residues))\n",
    "        sc_seq = ''.join(sc_residues)\n",
    "        full_scramble_dict[seq] = sc_seq\n",
    "    return full_scramble_dict\n",
    "\n",
    "def patterned_scrambler(sequence_list):\n",
    "    '''Function for creating patterned scrambled designs\n",
    "    In which hydrophobic or polar residues are shuffled to different positions with the same h or p character\n",
    "    prolines and glycines are kept in original positions\n",
    "    based on criteria described in in Rocklin, et al. 2017\n",
    "    Takes a list of original design sequences\n",
    "    Outputs a data frame with the original sequence, pattern of H/P/Pro/Gly, and the patterned scramble sequence'''\n",
    "\n",
    "    patterned_scramble_dict = {}\n",
    "    #Rocklin term these polar if they occur in a helix: D, E, H, K, N, Q, R, S, T, or Y\n",
    "    #A, F, I, L, M, V, W, and Y used to count number of hydrophobic aa\n",
    "    #I just used hydrophobic and polar definitions from default resfile categories\n",
    "    hydrophobics_list = ['A', 'F', 'I', 'L', 'M', 'V', 'W', 'Y']\n",
    "    polar_list = ['D', 'E', 'H', 'K', 'N', 'Q', 'R', 'S', 'T']\n",
    "    seq_pattern_dict = {}\n",
    "\n",
    "    for seq in sequence_list:\n",
    "        residues = list(seq)\n",
    "        patterned_res = []\n",
    "        hydrophobic_residues = []\n",
    "        polar_residues = []\n",
    "        patterned_scramble_res = []\n",
    "        for res in residues:\n",
    "            if res == 'P':\n",
    "                patterned_res.append('Pro')\n",
    "\n",
    "            elif res == 'G':\n",
    "                patterned_res.append('G')\n",
    "\n",
    "            elif res in hydrophobics_list:\n",
    "                patterned_res.append('H')\n",
    "                hydrophobic_residues.append(res)\n",
    "\n",
    "            elif res in polar_list:\n",
    "                patterned_res.append('P')\n",
    "                polar_residues.append(res)\n",
    "\n",
    "            else:\n",
    "                print('Cys found!')\n",
    "\n",
    "        seq_pattern = ''.join(patterned_res)\n",
    "        seq_pattern_dict[seq] = seq_pattern\n",
    "\n",
    "        for res in patterned_res:\n",
    "\n",
    "            if res == 'Pro':\n",
    "                patterned_scramble_res.append('P')\n",
    "            elif res == 'G':\n",
    "                patterned_scramble_res.append('G')\n",
    "            elif res == 'H':\n",
    "                l = random.randint(0, len(hydrophobic_residues)-1)\n",
    "                r = hydrophobic_residues.pop(l)\n",
    "                patterned_scramble_res.append(r)\n",
    "            elif res == 'P':\n",
    "                l = random.randint(0, len(polar_residues)-1)\n",
    "                r = polar_residues.pop(l)\n",
    "                patterned_scramble_res.append(r)\n",
    "        pattern_scramble_seq = ''.join(patterned_scramble_res)\n",
    "        patterned_scramble_dict[seq] = pattern_scramble_seq\n",
    "\n",
    "    df_name_pattern = pd.DataFrame.from_dict(seq_pattern_dict, orient='index', columns=['Seq HP pattern'])\n",
    "    df_name_pattern.index.name = 'Insert protein sequence'\n",
    "    df_name_pattern.reset_index(inplace=True)\n",
    "\n",
    "    df_name_pattern_sc = pd.DataFrame.from_dict(patterned_scramble_dict, orient='index', columns=['patterned_scramble_sequence'])\n",
    "    df_name_pattern_sc.index.name = 'Insert protein sequence'\n",
    "    df_name_pattern_sc.reset_index(inplace=True)\n",
    "\n",
    "    df = pd.merge(df_name_pattern, df_name_pattern_sc, on='Insert protein sequence')\n",
    "\n",
    "    return df\n",
    "\n",
    "####\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a746b1b",
   "metadata": {},
   "source": [
    "###Candidate switch WT sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "8186fc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of WT candidate switch sequences for R3 library: 53\n",
      "Number of switch candidates from ad method: 29\n",
      "Number of switch candidates from residuals method: 24\n"
     ]
    }
   ],
   "source": [
    "ad_method_df = pd.read_csv('/Users/stephaniecrilly/Library/CloudStorage/Box-Box/kortemmelab/home/scrilly/helix_sliding/20260108_switch_candidates_analysis/r2-hs_ad_scramble_vs_design_msd_only.csv')\n",
    "residuals_method_df = pd.read_csv('/Users/stephaniecrilly/Library/CloudStorage/Box-Box/kortemmelab/home/scrilly/helix_sliding/20260108_switch_candidates_analysis/r2-hs_ts_prot_MSD_stable_residuals_zscore_above2.csv')\n",
    "\n",
    "ad_method_df_short = ad_method_df[['Name', 'mean_kd', 'mean_ss']].copy()\n",
    "ad_method_df_short['mutant_type'] = 'wt_ad_method'\n",
    "\n",
    "residuals_method_df_short = residuals_method_df[['Name', 'mean_kd', 'mean_ss']].copy()\n",
    "residuals_method_df_short['mutant_type'] = 'wt_residuals_method'\n",
    "\n",
    "all_wt_switch_seqs_df = pd.concat([ad_method_df_short, residuals_method_df_short], ignore_index=True)\n",
    "\n",
    "#get original full sequence for creating scrambles\n",
    "r2_msd_df = pd.read_csv('/Users/stephaniecrilly/Library/CloudStorage/Box-Box/kortemmelab/home/scrilly/helix_sliding/20250604_r2_hs_lib/final_order/r2_msd_designs_final.csv')\n",
    "r2_msd_df_short = r2_msd_df[['shortname', 'sequence', 'final_sequence']].copy()\n",
    "\n",
    "#get relevant designs for r3 lib\n",
    "r2_msd_df_short = r2_msd_df_short.query('shortname in @all_wt_switch_seqs_df.Name', engine='python').copy()\n",
    "\n",
    "all_wt_switch_seqs_df = pd.merge(all_wt_switch_seqs_df, r2_msd_df_short, left_on='Name', right_on='shortname', how='left')\n",
    "all_wt_switch_seqs_df.drop(columns=['shortname'], inplace=True)\n",
    "all_wt_switch_seqs_df.rename(columns={'sequence':'og_full_sequence'}, inplace=True)\n",
    "\n",
    "#create truncated sequence without residues C-terminal to alfa tag\n",
    "all_wt_switch_seqs_df['final_sequence'] = all_wt_switch_seqs_df['og_full_sequence'].str.split('SRLEEELRRRLTE').str[0] + 'SRLEEELRRRLTE'\n",
    "\n",
    "#replace N-term residues with 'GA'\n",
    "all_wt_switch_seqs_df['final_sequence'] = 'GA' + all_wt_switch_seqs_df['final_sequence'].str[2:]\n",
    "\n",
    "#rename col\n",
    "all_wt_switch_seqs_df.rename(columns={'final_sequence':'Sequence'}, inplace=True)\n",
    "\n",
    "print(f'Total number of WT candidate switch sequences for R3 library: {all_wt_switch_seqs_df.shape[0]}')\n",
    "print(f'Number of switch candidates from ad method: {all_wt_switch_seqs_df[all_wt_switch_seqs_df[\"mutant_type\"]==\"wt_ad_method\"].shape[0]}')\n",
    "print(f'Number of switch candidates from residuals method: {all_wt_switch_seqs_df[all_wt_switch_seqs_df[\"mutant_type\"]==\"wt_residuals_method\"].shape[0]}')\n",
    "\n",
    "r3_all_ordered_seqs_list.append(all_wt_switch_seqs_df[['Name', 'Sequence', 'mutant_type']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d791732c",
   "metadata": {},
   "source": [
    "####Single mutant sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "700589da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of single mutant candidate switch sequences for R3 library: 2883\n",
      "Number of single mutant state 1:  1736\n",
      "Number of single mutant state 2:  0\n",
      "Number of single mutant divergent states:  16\n"
     ]
    }
   ],
   "source": [
    "single_mutants_df = pd.read_csv('/Users/stephaniecrilly/Library/CloudStorage/Box-Box/kortemmelab/home/scrilly/helix_sliding/20260122_CB_point_mutants/20260120_msd_bbs/all_msd_switch_candidates_single_mutants_state1_state2.csv')\n",
    "\n",
    "#create truncated sequence without residues C-terminal to alfa tag\n",
    "single_mutants_df['final_sequence'] = single_mutants_df['sequence'].str.split('SRLEEELRRRLTE').str[0] + 'SRLEEELRRRLTE'\n",
    "\n",
    "#replace N-term residues with 'GA'\n",
    "single_mutants_df['final_sequence'] = 'GA' + single_mutants_df['final_sequence'].str[2:]\n",
    "\n",
    "#rename shortname column\n",
    "single_mutants_df.rename(columns={'name':'Name', 'final_sequence':'Sequence'}, inplace=True)\n",
    "\n",
    "print(f'Total number of single mutant candidate switch sequences for R3 library: {single_mutants_df.shape[0]}')\n",
    "#TODO: fix counts to not include divergent ones\n",
    "print('Number of single mutant state 1: ', single_mutants_df[single_mutants_df[\"mutant_type\"].str.contains(r\"[\\w-]+state1\")].shape[0])\n",
    "print('Number of single mutant state 2: ', single_mutants_df[single_mutants_df[\"mutant_type\"].str.contains(r\"single[\\w-]+state2\")].shape[0])\n",
    "print('Number of single mutant divergent states: ', single_mutants_df[single_mutants_df[\"mutant_type\"].str.contains(\"state\\d+_\")].shape[0])\n",
    "\n",
    "r3_all_ordered_seqs_list.append(single_mutants_df[['Name', 'Sequence', 'mutant_type']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4edce7c",
   "metadata": {},
   "source": [
    "####Double mutant sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "c4b158d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of double mutant candidate switch sequences for R3 library: 2408\n",
      "Number of double mutant state 1: 342\n",
      "Number of double mutant state 2: 2066\n"
     ]
    }
   ],
   "source": [
    "double_mutants_df = pd.read_csv('/Users/stephaniecrilly/Library/CloudStorage/Box-Box/kortemmelab/home/scrilly/helix_sliding/20260122_CB_point_mutants/20260120_msd_bbs/all_msd_switch_candidates_double_mutants.csv')\n",
    "\n",
    "#create truncated sequence without residues C-terminal to alfa tag\n",
    "double_mutants_df['final_sequence'] = double_mutants_df['sequence'].str.split('SRLEEELRRRLTE').str[0] + 'SRLEEELRRRLTE'\n",
    "\n",
    "#replace N-term residues with 'GA'\n",
    "double_mutants_df['final_sequence'] = 'GA' + double_mutants_df['final_sequence'].str[2:]\n",
    "\n",
    "#rename col\n",
    "double_mutants_df.rename(columns={'final_sequence':'Sequence'}, inplace=True)\n",
    "\n",
    "print(f'Total number of double mutant candidate switch sequences for R3 library: {double_mutants_df.shape[0]}')\n",
    "print(f'Number of double mutant state 1: {double_mutants_df[double_mutants_df[\"mutant_type\"].str.contains(\"state1\")].shape[0]}')\n",
    "print(f'Number of double mutant state 2: {double_mutants_df[double_mutants_df[\"mutant_type\"].str.contains(\"state2\")].shape[0]}')\n",
    "\n",
    "r3_all_ordered_seqs_list.append(double_mutants_df[['Name', 'Sequence', 'mutant_type']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "0e36096d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of double mutant candidate switch sequences for 375 without N-term GA for R3 library: 80\n"
     ]
    }
   ],
   "source": [
    "#create double mutants for 375 without N-term GA\n",
    "#for comparison to previous libraries\n",
    "\n",
    "double_mutants_375_df = double_mutants_df.query('Name.str.contains(\"375\")', engine='python').copy()\n",
    "\n",
    "#revert N-term GA to original residues\n",
    "double_mutants_375_df['Sequence'] = 'EE' + double_mutants_375_df['Sequence'].str[2:]\n",
    "double_mutants_375_df['Name'] = double_mutants_375_df['Name'] + '-og-N-term'\n",
    "\n",
    "print(f'Total number of double mutant candidate switch sequences for 375 without N-term GA for R3 library: {double_mutants_375_df.shape[0]}')\n",
    "\n",
    "r3_all_ordered_seqs_list.append(double_mutants_375_df[['Name', 'Sequence', 'mutant_type']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67568a1f",
   "metadata": {},
   "source": [
    "####Control sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "32dd250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scramble_seq_dfs = []\n",
    "\n",
    "scrambles_df = all_wt_switch_seqs_df.copy()\n",
    "scrambles_df['duplicated_sequence'] = scrambles_df['Sequence'].str.split('SRLEEELRRRLTE').str[0]\n",
    "\n",
    "#full scrambles\n",
    "full_scramble_dict = full_scrambler(scrambles_df['duplicated_sequence'].tolist())\n",
    "scrambles_df['full_scramble_sequence'] = scrambles_df['duplicated_sequence'].map(full_scramble_dict)\n",
    "scrambles_df['full_scramble_sequence'] = scrambles_df['full_scramble_sequence'] + 'SRLEEELRRRLTE'\n",
    "\n",
    "#update name\n",
    "scrambles_df['shortname_full'] = scrambles_df['Name'] + '_full_scramble'\n",
    "full_scrambles_df_subset = scrambles_df[['shortname_full', 'full_scramble_sequence']]\n",
    "full_scrambles_df_subset = full_scrambles_df_subset.rename(columns={'shortname_full': 'Name', 'full_scramble_sequence': 'Sequence'})\n",
    "full_scrambles_df_subset['mutant_type'] = 'full_scramble'\n",
    "scramble_seq_dfs.append(full_scrambles_df_subset)\n",
    "\n",
    "\n",
    "#patterned scrambles\n",
    "patterned_scramble_df = patterned_scrambler(scrambles_df['duplicated_sequence'].tolist())\n",
    "scrambles_df = pd.merge(scrambles_df, patterned_scramble_df, left_on='duplicated_sequence', right_on='Insert protein sequence', how='left')\n",
    "scrambles_df['patterned_scramble_sequence'] = scrambles_df['patterned_scramble_sequence'] + 'SRLEEELRRRLTE'\n",
    "\n",
    "#update name\n",
    "scrambles_df['shortname_pat'] = scrambles_df['Name'] + '_patterned_scramble'\n",
    "pat_scrambles_df_subset = scrambles_df[['shortname_pat', 'patterned_scramble_sequence']]\n",
    "pat_scrambles_df_subset = pat_scrambles_df_subset.rename(columns={'shortname_pat': 'Name', 'patterned_scramble_sequence': 'Sequence'})\n",
    "pat_scrambles_df_subset['mutant_type'] = 'patterned_scramble'\n",
    "scramble_seq_dfs.append(pat_scrambles_df_subset)\n",
    "\n",
    "\n",
    "#ad scrambles old way\n",
    "ad_scrambles_df = r2_msd_df.query('shortname in @all_wt_switch_seqs_df.Name', engine='python').copy()\n",
    "\n",
    "#make second final_sequence column that will match the h1 and h2 helices without N-term GA\n",
    "ad_scrambles_df['final_sequence_for_ad'] = ad_scrambles_df['sequence']\n",
    "\n",
    "#make msd ad to ala scrambles\n",
    "msd_scrambles_df = a_d_to_ala(ad_scrambles_df, state='msd', mode='old')\n",
    "msd_scrambles_df_new = a_d_to_ala(ad_scrambles_df, state='msd', mode='new')\n",
    "\n",
    "#make ALFA tag C-terminal\n",
    "msd_scrambles_df['a_d_to_ala_sequence'] = msd_scrambles_df['a_d_to_ala_sequence'].str.split('SRLEEELRRRLTE').str[0] + 'SRLEEELRRRLTE'\n",
    "msd_scrambles_df_new['a_d_to_ala_sequence'] = msd_scrambles_df_new['a_d_to_ala_sequence'].str.split('SRLEEELRRRLTE').str[0] + 'SRLEEELRRRLTE'\n",
    "\n",
    "#replace N-term residues with 'GA'\n",
    "msd_scrambles_df['a_d_to_ala_sequence'] = 'GA' + msd_scrambles_df['a_d_to_ala_sequence'].str[2:]\n",
    "msd_scrambles_df_new['a_d_to_ala_sequence'] = 'GA' + msd_scrambles_df_new['a_d_to_ala_sequence'].str[2:]\n",
    "\n",
    "msd_scrambles_df['shortname'] = msd_scrambles_df['shortname'] + '_ad_scramble'\n",
    "msd_scrambles_df_new['shortname'] = msd_scrambles_df_new['shortname'] + '_ad_scramble_new'\n",
    "\n",
    "msd_scrambles_df_subset = msd_scrambles_df[['shortname', 'a_d_to_ala_sequence']]\n",
    "msd_scrambles_df_subset = msd_scrambles_df_subset.rename(columns={'shortname':'Name', 'a_d_to_ala_sequence': 'Sequence'})\n",
    "msd_scrambles_df_subset['mutant_type'] = 'ad_scramble_old_method'\n",
    "scramble_seq_dfs.append(msd_scrambles_df_subset)\n",
    "\n",
    "msd_scrambles_df_new_subset = msd_scrambles_df_new[['shortname', 'a_d_to_ala_sequence']]\n",
    "msd_scrambles_df_new_subset = msd_scrambles_df_new_subset.rename(columns={'shortname':'Name', 'a_d_to_ala_sequence': 'Sequence'})\n",
    "msd_scrambles_df_new_subset['mutant_type'] = 'ad_scramble_new_method'\n",
    "scramble_seq_dfs.append(msd_scrambles_df_new_subset)\n",
    "\n",
    "all_scramble_seqs_df = pd.concat(scramble_seq_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "2c9569c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of scramble sequences before removing duplicates: 596\n",
      "Total number of scramble sequences after removing duplicates: 497\n"
     ]
    }
   ],
   "source": [
    "#import 384 scrambles from previous r2 lib, find their corresponding design as well\n",
    "r2_scramble_seqs_df = pd.read_csv('/Users/stephaniecrilly/Library/CloudStorage/Box-Box/kortemmelab/home/scrilly/helix_sliding/20250604_r2_hs_lib/final_order/scramble_seqs_final.csv')\n",
    "#TODO: will need to fill in mutant type for r2 scrambles\n",
    "r2_scramble_seqs_df['mutant_type'] = 'r2_existing_scramble'\n",
    "\n",
    "concat_scrambles_df = pd.concat([r2_scramble_seqs_df, all_scramble_seqs_df], ignore_index=True)\n",
    "print(f'Total number of scramble sequences before removing duplicates: {concat_scrambles_df.shape[0]}')\n",
    "\n",
    "#if scramble already exists from r2 lib, drop the new one\n",
    "concat_scrambles_df = concat_scrambles_df.drop_duplicates(subset=['Name'], keep='first')\n",
    "print(f'Total number of scramble sequences after removing duplicates: {concat_scrambles_df.shape[0]}')\n",
    "\n",
    "r3_all_ordered_seqs_list.append(concat_scrambles_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "29f8d5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of bespoke control sequences for R3 library: 16\n"
     ]
    }
   ],
   "source": [
    "#make df with additional control seqs from Bram and 375 and point mutants\n",
    "bespoke_ctrls_dict = {'bmp38' : 'GARLAQLKQERAALKQRLAALDQEIAALEWQIQSDPRKKQLYQRLLALISDRFALEQRIAALDQEIAALEAG', \n",
    "                 'bmp53' : 'GARLEELIAERLRLVGDLVDLDREIAALEQQIQSDPRKKQLEQRLAALKQERAALEQRIAALDWEIADLDDG', \n",
    "                 'bmp42' : 'GARLAQLKQERAALKQRLDALDQEIAALEWQIQSDPRKKQLYQRLLELIGERLALMGDIFELDVEIAALEAG', \n",
    "                 'bmp45' : 'GARLAQLKQERAALKQRLEALDQEIAALEWQIQSDPRKKQLLQRLYELFGERLALFGDIFDLDVEIAALEAG', \n",
    "                 'bmp51' : 'GARLAQLKQERAALKQRLDALEQEIAALEWQIQSDPRKKQLQQRLRQLYGERLRLESDIFDLDVEIAALEAG', \n",
    "                 'bmp57' : 'GARLAQLKQERAALKQRLEALDQEIAALEWQIQSDPRKKQLLQRLRRLYGERLALFGDIFDLDVEIAALEAG', \n",
    "                 'bmp23' : 'GARLAQLKQERAALKQRLAALDQEIAALEWQIQSPDRKKQLEQRLAALKQERAALEQRIAALDQEIAALEAG',\n",
    "                 '375' : 'EELKRIEEEIAAIEREIARAEEKLKAQESDPRKKGLQAEREKLLEKLAELRKERERLSRLEEELRRRLTELRRRLE',\n",
    "                 '375-GA-cdel' : 'GALKRIEEEIAAIEREIARAEEKLKAQESDPRKKGLQAEREKLLEKLAELRKERERLSRLEEELRRRLTE',\n",
    "                '375-ad-to-A-GA-cdel' : 'GAAKRAEEEAAAAEREAARAEEKAKAQESDPRKKGLQAEAEKALEKAAEARKEAERASRLEEELRRRLTE',\n",
    "                 '375-ad-to-A-cdel' : 'EEAKRAEEEAAAAEREAARAEEKAKAQESDPRKKGLQAEAEKALEKAAEARKEAERASRLEEELRRRLTE', \n",
    "                 '375-cdel' : 'EELKRIEEEIAAIEREIARAEEKLKAQESDPRKKGLQAEREKLLEKLAELRKERERLSRLEEELRRRLTE', \n",
    "                 '375-G35Q-cdel' : 'EELKRIEEEIAAIEREIARAEEKLKAQESDPRKKQLQAEREKLLEKLAELRKERERLSRLEEELRRRLTE', \n",
    "                 '375-G35Q-GA-cdel' : 'GALKRIEEEIAAIEREIARAEEKLKAQESDPRKKQLQAEREKLLEKLAELRKERERLSRLEEELRRRLTE',\n",
    "                 '375-L36K-cdel' : 'EELKRIEEEIAAIEREIARAEEKLKAQESDPRKKGKQAEREKLLEKLAELRKERERLSRLEEELRRRLTE',\n",
    "                 '375-L36Q-cdel' : 'EELKRIEEEIAAIEREIARAEEKLKAQESDPRKKGQQAEREKLLEKLAELRKERERLSRLEEELRRRLTE'}\n",
    "\n",
    "#make df with columns 'Name and 'sequence' from dict\n",
    "bespoke_ctrls_df = pd.DataFrame.from_dict(bespoke_ctrls_dict, orient='index', columns=['Sequence']).reset_index().rename(columns={'index': 'Name'})\n",
    "bespoke_ctrls_df['mutant_type'] = 'bespoke_control'\n",
    "print(f'Total number of bespoke control sequences for R3 library: {bespoke_ctrls_df.shape[0]}')\n",
    "\n",
    "r3_all_ordered_seqs_list.append(bespoke_ctrls_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "a3bffe1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of SSD WT sequences corresponding to SSD scramble controls for R3 library: 64\n"
     ]
    }
   ],
   "source": [
    "#for all ssd seqs in scramble controls, get the wt seq\n",
    "r2_ssd_df = pd.read_csv('/Users/stephaniecrilly/Library/CloudStorage/Box-Box/kortemmelab/home/scrilly/helix_sliding/20250604_r2_hs_lib/final_order/r2_ssd_designs_final.csv')\n",
    "\n",
    "#filter concat scrambles df to get ssd only\n",
    "ssd_scramble_seqs_df = concat_scrambles_df[concat_scrambles_df['Name'].str.contains('SSD')].copy()\n",
    "ssd_scramble_seqs_df['Name'] = ssd_scramble_seqs_df['Name'].str.replace('_full_scramble', '', regex=False)\n",
    "ssd_scramble_seqs_df['Name'] = ssd_scramble_seqs_df['Name'].str.replace('_ad_scramble', '', regex=False)\n",
    "ssd_scramble_seqs_df['Name'] = ssd_scramble_seqs_df['Name'].str.replace('_patterned_scramble', '', regex=False)\n",
    "\n",
    "ssd_scramble_seqs_df.drop_duplicates(subset=['Name'], keep='first', inplace=True)\n",
    "\n",
    "#filter r2_ssd_df to only those in ssd_scramble_seqs_df\n",
    "ssd_wt_seqs_df = r2_ssd_df[r2_ssd_df['shortname'].isin(ssd_scramble_seqs_df['Name'])].copy()\n",
    "ssd_wt_seqs_df = ssd_wt_seqs_df[['shortname', 'final_sequence']].rename(columns={'shortname':'Name', 'final_sequence':'Sequence'})\n",
    "ssd_wt_seqs_df['mutant_type'] = 'ssd_r2'\n",
    "\n",
    "print(f'Total number of SSD WT sequences corresponding to SSD scramble controls for R3 library: {ssd_wt_seqs_df.shape[0]}')\n",
    "\n",
    "r3_all_ordered_seqs_list.append(ssd_wt_seqs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defd7191",
   "metadata": {},
   "source": [
    "####Generate final dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "69accca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbr of total sequences in r3 library: 6000\n"
     ]
    }
   ],
   "source": [
    "r3_all_df = pd.concat(r3_all_ordered_seqs_list, ignore_index=True)\n",
    "\n",
    "r3_all_df.drop_duplicates(subset=['Sequence'], keep='first', inplace=True)\n",
    "    #above returns one duplicate\n",
    "    #design MSD-exp_bbs-mpnn-205_ad_scramble with new and old method produce same sequence\n",
    "    #keep this duplicate\n",
    "\n",
    "r3_all_df.to_csv(f'{outdir}/r3_hs_all_protein_seqs_final.csv', index=False)\n",
    "\n",
    "print(f'Numbr of total sequences in r3 library: {r3_all_df.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "ce4abd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of R3 sequences already codon optimized in R2 lib: 504\n",
      "Number of R3 sequences NEEDING codon optimization: 5496\n"
     ]
    }
   ],
   "source": [
    "#get all nucleotide sequences that were submitted for r2 hs final submission\n",
    "r2_hs_final_submitted_seqs = pd.read_csv('/Users/stephaniecrilly/Library/CloudStorage/Box-Box/kortemmelab/home/scrilly/helix_sliding/20250604_r2_hs_lib/20250716_r2_hs_final_submission/20250716_r2_hs_final_submission.csv')\n",
    "\n",
    "#get nucleotide sequences for r3 designs that were already codon optimized in r2 lib\n",
    "r3_codon_opt_seqs_df = r2_hs_final_submitted_seqs[r2_hs_final_submitted_seqs['Name'].isin(r3_all_df['Name'])].copy()\n",
    "print(f'Number of R3 sequences already codon optimized in R2 lib: {r3_codon_opt_seqs_df.shape[0]}')\n",
    "\n",
    "r3_codon_opt_seqs_df.to_csv(f'{outdir}/r3_hs_codon_optimized_seqs_from_r2_lib.csv', index=False)\n",
    "\n",
    "#for all others, export as new df for codon opt\n",
    "r3_NEEDS_codon_opt_seqs_df = r3_all_df[~r3_all_df['Name'].isin(r3_codon_opt_seqs_df['Name'])].copy()\n",
    "print(f'Number of R3 sequences NEEDING codon optimization: {r3_NEEDS_codon_opt_seqs_df.shape[0]}')\n",
    "\n",
    "r3_NEEDS_codon_opt_seqs_df.to_csv(f'{outdir}/r3_hs_seqs_needing_codon_optimization.csv', index=False)\n",
    "\n",
    "#504 seqs already codon optimized in r2\n",
    "#if add up r2 scranbles controls (384),\n",
    "#bespoke controls (16),\n",
    "#and ssd wt for scrambles (64)\n",
    "#and wt switch candidates (53), get 517\n",
    "#missing 13 are newly added bespoke controls (375-GA-cdel, 375-ad-to-A-GA-cdel, 375-G35Q-GA-cdel)\n",
    "#and 10 SSD designs from r2 that were not ordered for some reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "c92fa957",
   "metadata": {},
   "outputs": [],
   "source": [
    "#why are all ssd seqs 71 residues long\n",
    "#not all are\n",
    "#there are 31 ssd seqs that are alfa thread 53, bm01 loop\n",
    "#each of these has a scramble, so total is 124\n",
    "# r2_all_seqs_df = pd.read_csv('/Users/stephaniecrilly/Library/CloudStorage/Box-Box/kortemmelab/home/scrilly/helix_sliding/20250604_r2_hs_lib/final_order/r2_hs_all_protein_seqs_final.csv')\n",
    "\n",
    "# r3_all_df['length'] = r3_all_df['Sequence'].str.len()\n",
    "# r3_all_df_71 = r3_all_df[r3_all_df['length'] == 71].copy()\n",
    "# print(r3_all_df_71.shape)\n",
    "\n",
    "# r2_ssd_df = pd.read_csv('/Users/stephaniecrilly/Library/CloudStorage/Box-Box/kortemmelab/home/scrilly/helix_sliding/20250604_r2_hs_lib/final_order/r2_ssd_designs_final.csv')\n",
    "\n",
    "# merge_df = pd.merge(r3_all_df_71, r2_ssd_df, left_on='Sequence', right_on='final_sequence', how='inner', indicator=True)\n",
    "# merge_df.to_csv('/Users/stephaniecrilly/downloads/r3_71mer_vs_r2_ssd_merge.csv', index=False)\n",
    "\n",
    "# r3_remaining_71mer_df = r3_all_df_71[~r3_all_df_71['Sequence'].isin(merge_df['Sequence'])].copy()\n",
    "# r3_remaining_71mer_df.to_csv('/Users/stephaniecrilly/Downloads/r3_71mer_not_in_r2_ssd.csv', index=False)\n",
    "# print(merge_df.shape)\n",
    "# print(r3_remaining_71mer_df.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plotting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
