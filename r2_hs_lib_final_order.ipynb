{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "db4cfd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "b71f5c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1_hs_seqs_path = '/Users/stephaniecrilly/Library/CloudStorage/Box-Box/kortemmelab/home/scrilly/helix_sliding/20231212_final_analysis_r1_order/20231221_final_order/20231221_all_design_sets_r1_order.csv'\n",
    "r2_ssd_seqs_path = '/Users/stephaniecrilly/Library/CloudStorage/Box-Box/kortemmelab/home/scrilly/helix_sliding/20250604_r2_hs_lib/metric_files/ssd/ssd_designs_passing.csv'\n",
    "r2_msd_seqs_path = '/Users/stephaniecrilly/Library/CloudStorage/Box-Box/kortemmelab/home/scrilly/helix_sliding/20250604_r2_hs_lib/metric_files/msd/msd_designs_passing.csv'\n",
    "r2_msd_exp_bbs_seqs_path = '/Users/stephaniecrilly/Library/CloudStorage/Box-Box/kortemmelab/home/scrilly/helix_sliding/20250604_r2_hs_lib/metric_files/msd_exp_bbs/exp_bbs_msd_designs_passing.csv'\n",
    "r2_msd_scale_up_seqs_path = '/Users/stephaniecrilly/Library/CloudStorage/Box-Box/kortemmelab/home/scrilly/helix_sliding/20250604_r2_hs_lib/metric_files/msd_f2s_os_scaled_up/outputs/msd_designs_passing.csv'\n",
    "\n",
    "outdir = '/Users/stephaniecrilly/Library/CloudStorage/Box-Box/kortemmelab/home/scrilly/helix_sliding/20250604_r2_hs_lib/final_order'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d41ff6",
   "metadata": {},
   "source": [
    "# Single state designs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "24fb9153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 SSD designs: 495\n",
      "R2 SSD unique backbones: 223\n"
     ]
    }
   ],
   "source": [
    "r2_ssd_df = pd.read_csv(r2_ssd_seqs_path)\n",
    "print(f'R2 SSD designs: {r2_ssd_df.shape[0]}')\n",
    "print(f'R2 SSD unique backbones: {r2_ssd_df.bb_id.nunique()}')\n",
    "\n",
    "r2_ssd_df['design_class'] = r2_ssd_df['state_design'] + '-' + r2_ssd_df['seq_method']\n",
    "\n",
    "#create truncated sequence without residues C-terminal to alfa tag\n",
    "r2_ssd_df['final_sequence'] = r2_ssd_df['sequence'].str.split('SRLEEELRRRLTE').str[0] + 'SRLEEELRRRLTE'\n",
    "\n",
    "#replace N-term residues with 'GA'\n",
    "r2_ssd_df['final_sequence'] = 'GA' + r2_ssd_df['final_sequence'].str[2:]\n",
    "\n",
    "#make a shortname column that is the design class plus a number that increases for each row\n",
    "r2_ssd_df = r2_ssd_df.reset_index()\n",
    "r2_ssd_df['shortname'] = r2_ssd_df['design_class'] + '-' + r2_ssd_df.index.astype(str)\n",
    "\n",
    "#filter out sequences in r1_hs lib\n",
    "#will add these separately as same nt seqs as r1 order\n",
    "\n",
    "r1_hs_seqs_path = '/Users/stephaniecrilly/Library/CloudStorage/Box-Box/kortemmelab/home/scrilly/helix_sliding/20231212_final_analysis_r1_order/20231221_final_order/20231221_all_design_sets_r1_order.csv'\n",
    "r1_hs_df = pd.read_csv(r1_hs_seqs_path)\n",
    "r2_ssd_no_r1_df = r2_ssd_df.query('not sequence.isin(@r1_hs_df.sequence)', engine='python').copy()\n",
    "\n",
    "#get shortname and sequence column only\n",
    "r2_ssd_short_df = r2_ssd_no_r1_df[['shortname', 'final_sequence']]\n",
    "\n",
    "r2_ssd_df.to_csv(f'{outdir}/r2_ssd_designs_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467d0323",
   "metadata": {},
   "source": [
    "# Multistate designs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "b9de5ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 MSD for designable bbs designs: 121\n",
      "Unique bb pairs for R2 MSD F2S scaled up designs: 65\n",
      "R2 MSD for experimental bbs designs: 153\n",
      "Unique bb pairs for R2 MSD exp bbs designs: 1\n",
      "R2 MSD for F2S scaled up designs: 326\n",
      "Unique bb pairs for R2 MSD F2S scaled up designs: 58\n"
     ]
    }
   ],
   "source": [
    "####MSD for designable bbs####\n",
    "r2_msd_df = pd.read_csv(r2_msd_seqs_path)\n",
    "print(f'R2 MSD for designable bbs designs: {r2_msd_df.sequence.nunique()}')\n",
    "\n",
    "#make a shortname column that is the design class plus a number that increases for each row\n",
    "r2_msd_df['design_class'] = r2_msd_df['state_design_min0'] + '-' + r2_msd_df['seq_design_method_min0'].str.lower()\n",
    "\n",
    "#create truncated sequence without residues C-terminal to alfa tag\n",
    "r2_msd_df['final_sequence'] = r2_msd_df['sequence'].str.split('SRLEEELRRRLTE').str[0] + 'SRLEEELRRRLTE'\n",
    "\n",
    "#replace N-term residues with 'GA'\n",
    "r2_msd_df['final_sequence'] = 'GA' + r2_msd_df['final_sequence'].str[2:]\n",
    "\n",
    "#make new column for bb id pair\n",
    "r2_msd_df['msd_bbs_id'] = r2_msd_df['min0_bb_id_min0'] + '_' + r2_msd_df['min2_bb_id_min0']\n",
    "print(f\"Unique bb pairs for R2 MSD F2S scaled up designs: {r2_msd_df['msd_bbs_id'].nunique()}\") #may be an overestimate bc of diff naming conventions (65-24=41 at lowest)\n",
    "\n",
    "####MSD for experimental bbs####\n",
    "r2_msd_exp_bbs_df = pd.read_csv(r2_msd_exp_bbs_seqs_path)\n",
    "print(f'R2 MSD for experimental bbs designs: {r2_msd_exp_bbs_df.sequence.nunique()}')   \n",
    "\n",
    "#create truncated sequence without residues C-terminal to alfa tag\n",
    "r2_msd_exp_bbs_df['final_sequence'] = r2_msd_exp_bbs_df['sequence'].str.split('SRLEEELRRRLTE').str[0] + 'SRLEEELRRRLTE'\n",
    "\n",
    "#replace N-term residues with 'GA'\n",
    "r2_msd_exp_bbs_df['final_sequence'] = 'GA' + r2_msd_exp_bbs_df['final_sequence'].str[2:]\n",
    "\n",
    "#make a shortname column that is the design class plus a number that increases for each row\n",
    "r2_msd_exp_bbs_df['design_class'] = r2_msd_exp_bbs_df['state_design_min0'] + '-exp_bbs-' + r2_msd_exp_bbs_df['seq_design_method_min0'].str.lower()\n",
    "print(f'Unique bb pairs for R2 MSD exp bbs designs: 1')\n",
    "\n",
    "####MSD F2S scaled up####\n",
    "r2_msd_scale_up_df = pd.read_csv(r2_msd_scale_up_seqs_path)\n",
    "print(f'R2 MSD for F2S scaled up designs: {r2_msd_scale_up_df.sequence.nunique()}')\n",
    "\n",
    "#create truncated sequence without residues C-terminal to alfa tag\n",
    "r2_msd_scale_up_df['final_sequence'] = r2_msd_scale_up_df['sequence'].str.split('SRLEEELRRRLTE').str[0] + 'SRLEEELRRRLTE'\n",
    "\n",
    "#replace N-term residues with 'GA'\n",
    "r2_msd_scale_up_df['final_sequence'] = 'GA' + r2_msd_scale_up_df['final_sequence'].str[2:]\n",
    "\n",
    "#make a shortname column that is the design class plus a number that increases for each row\n",
    "r2_msd_scale_up_df['design_class'] = r2_msd_scale_up_df['state_design_min0'] + '-scale_up-' + r2_msd_scale_up_df['seq_design_method_min0'].str.lower()\n",
    "print(f\"Unique bb pairs for R2 MSD F2S scaled up designs: {r2_msd_scale_up_df['msd_bbs_id_min0'].nunique()}\")\n",
    "\n",
    "#full dfs to concat\n",
    "r2_msd_all_dfs_to_concat = [r2_msd_df, r2_msd_exp_bbs_df, r2_msd_scale_up_df]\n",
    "r2_msd_all_df = pd.concat(r2_msd_all_dfs_to_concat, ignore_index=True)\n",
    "\n",
    "#make a shortname column that is the design class plus a number that increases for each row\n",
    "r2_msd_all_df = r2_msd_all_df.reset_index()\n",
    "r2_msd_all_df['shortname'] = r2_msd_all_df['design_class'] + '-' + r2_msd_all_df.index.astype(str)\n",
    "\n",
    "#get shortname and sequence column only\n",
    "r2_msd_all_short_df = r2_msd_all_df[['shortname', 'final_sequence']]\n",
    "\n",
    "r2_msd_all_df.to_csv(f'{outdir}/r2_msd_designs_final.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69311b9e",
   "metadata": {},
   "source": [
    "# Multistate predicted as only one state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "b7daef0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of MSD designs predicted to min0 passing stringent filters: 9446\n",
      "Number of MSD designs predicted to min2 passing stringent filters: 572\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#take MSD sequences that are low RMSD to only one state, refilter for plddt > 90 and see how many\n",
    "r2_msd_min0_path = '/Users/stephaniecrilly/Library/CloudStorage/Box-Box/kortemmelab/home/scrilly/helix_sliding/20250604_r2_hs_lib/metric_files/msd/msd_designs_passing_min0_only.csv'\n",
    "r2_msd_min2_path = '/Users/stephaniecrilly/Library/CloudStorage/Box-Box/kortemmelab/home/scrilly/helix_sliding/20250604_r2_hs_lib/metric_files/msd/msd_designs_passing_min2_only.csv'\n",
    "\n",
    "####pred only min0####\n",
    "r2_msd_min0_df = pd.read_csv(r2_msd_min0_path)\n",
    "r2_msd_min0_df = r2_msd_min0_df.query('avg_plddt_no_loop > 90  & min0_all_rmsd_no_loop < 1.0 & avg_pae_no_loop < 5', engine='python').copy()\n",
    "print(f'Number of MSD designs predicted to min0 passing stringent filters: {r2_msd_min0_df.sequence.nunique()}')\n",
    "r2_msd_min0_df_subset = r2_msd_min0_df.sample(n=175, axis=0, random_state=42)\n",
    "\n",
    "#create truncated sequence without residues C-terminal to alfa tag\n",
    "r2_msd_min0_df_subset['final_sequence'] = r2_msd_min0_df_subset['sequence'].str.split('SRLEEELRRRLTE').str[0] + 'SRLEEELRRRLTE'\n",
    "\n",
    "#replace N-term residues with 'GA'\n",
    "r2_msd_min0_df_subset['final_sequence'] = 'GA' + r2_msd_min0_df_subset['final_sequence'].str[2:]\n",
    "\n",
    "#make a shortname column that is the design class plus a number that increases for each row\n",
    "r2_msd_min0_df_subset['design_class'] = r2_msd_min0_df_subset['state_design'] + '-min0-' + r2_msd_min0_df_subset['seq_design_method'].str.lower()\n",
    "\n",
    "####pred only min2####\n",
    "r2_msd_min2_df = pd.read_csv(r2_msd_min2_path)\n",
    "r2_msd_min2_df = r2_msd_min2_df.query('avg_plddt_no_loop > 90  & min2_all_rmsd_no_loop < 1.0  & avg_pae_no_loop < 5', engine='python').copy()\n",
    "print(f'Number of MSD designs predicted to min2 passing stringent filters: {r2_msd_min2_df.sequence.nunique()}')\n",
    "r2_msd_min2_df_subset = r2_msd_min2_df.sample(n=175, axis=0, random_state=42)\n",
    "\n",
    "#create truncated sequence without residues C-terminal to alfa tag\n",
    "r2_msd_min2_df_subset['final_sequence'] = r2_msd_min2_df_subset['sequence'].str.split('SRLEEELRRRLTE').str[0] + 'SRLEEELRRRLTE'\n",
    "\n",
    "#replace N-term residues with 'GA'\n",
    "r2_msd_min2_df_subset['final_sequence'] = 'GA' + r2_msd_min2_df_subset['final_sequence'].str[2:]\n",
    "\n",
    "#make a shortname column that is the design class plus a number that increases for each row\n",
    "r2_msd_min2_df_subset['design_class'] = r2_msd_min2_df_subset['state_design'] + '-min2-' + r2_msd_min2_df_subset['seq_design_method'].str.lower()\n",
    "\n",
    "#full dfs to concat\n",
    "r2_msd_one_state_dfs_to_concat = [r2_msd_min0_df_subset, r2_msd_min2_df_subset]\n",
    "r2_msd_one_state_df = pd.concat(r2_msd_one_state_dfs_to_concat, ignore_index=True)\n",
    "\n",
    "#make a shortname column that is the design class plus a number that increases for each row\n",
    "r2_msd_one_state_df = r2_msd_one_state_df.reset_index()\n",
    "r2_msd_one_state_df['shortname'] = r2_msd_one_state_df['design_class'] + '-' + r2_msd_one_state_df.index.astype(str)\n",
    "\n",
    "#get shortname and sequence column only\n",
    "r2_msd_one_state_short_df = r2_msd_one_state_df[['shortname', 'final_sequence']]\n",
    "\n",
    "r2_msd_one_state_df.to_csv(f'{outdir}/r2_msd_one_state_designs_final.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "09b46050",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if decide to turn first two res into GA run the following\n",
    "# df['final_sequence'] = df['final_sequence'].str[2:]\n",
    "# df['final_sequence'] = 'GA' + df['final_sequence']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba18caa1",
   "metadata": {},
   "source": [
    "# Control sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "73373e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make df with additional control seqs from Bram and 375 and point mutants\n",
    "#TODO: add alfa tag mutants with bm01 ctrl, add more conservative ad to ala\n",
    "bespoke_ctrls_dict = {'bmp38' : 'GARLAQLKQERAALKQRLAALDQEIAALEWQIQSDPRKKQLYQRLLALISDRFALEQRIAALDQEIAALEAG', \n",
    "                 'bmp53' : 'GARLEELIAERLRLVGDLVDLDREIAALEQQIQSDPRKKQLEQRLAALKQERAALEQRIAALDWEIADLDDG', \n",
    "                 'bmp31' : 'GARLAQLKQERAALKQRLAALDQEIAALEWQIQSDPRKKQLEQRLAALKQERAALEQRIAALDQEIAALEAG', \n",
    "                 'bmp36' : 'GARLAQLKQERAALEQRLAALDQEIAALEWQIQSDPRKKQLEQKLLELQAERLRLIGDIVNLDQQILNLEAG', \n",
    "                 'bmp42' : 'GARLAQLKQERAALKQRLDALDQEIAALEWQIQSDPRKKQLYQRLLELIGERLALMGDIFELDVEIAALEAG', \n",
    "                 'bmp45' : 'GARLAQLKQERAALKQRLEALDQEIAALEWQIQSDPRKKQLLQRLYELFGERLALFGDIFDLDVEIAALEAG', \n",
    "                 'bmp51' : 'GARLAQLKQERAALKQRLDALEQEIAALEWQIQSDPRKKQLQQRLRQLYGERLRLESDIFDLDVEIAALEAG', \n",
    "                 'bmp57' : 'GARLAQLKQERAALKQRLEALDQEIAALEWQIQSDPRKKQLLQRLRRLYGERLALFGDIFDLDVEIAALEAG', \n",
    "                 'bmp23' : 'GARLAQLKQERAALKQRLAALDQEIAALEWQIQSPDRKKQLEQRLAALKQERAALEQRIAALDQEIAALEAG',\n",
    "                 '375' : 'EELKRIEEEIAAIEREIARAEEKLKAQESDPRKKGLQAEREKLLEKLAELRKERERLSRLEEELRRRLTELRRRLE',\n",
    "                 '375-GA' : 'GALKRIEEEIAAIEREIARAEEKLKAQESDPRKKGLQAEREKLLEKLAELRKERERLSRLEEELRRRLTELRRRLE',\n",
    "                 '375-R74W' : 'EELKRIEEEIAAIEREIARAEEKLKAQESDPRKKGLQAEREKLLEKLAELRKERERLSRLEEELRRRLTELRRWLE',\n",
    "                 '375-L75W' : 'EELKRIEEEIAAIEREIARAEEKLKAQESDPRKKGLQAEREKLLEKLAELRKERERLSRLEEELRRRLTELRRRWE',\n",
    "                 '375-77W' : 'EELKRIEEEIAAIEREIARAEEKLKAQESDPRKKGLQAEREKLLEKLAELRKERERLSRLEEELRRRLTELRRRLEW',\n",
    "                 '375-77W-GA' : 'GALKRIEEEIAAIEREIARAEEKLKAQESDPRKKGLQAEREKLLEKLAELRKERERLSRLEEELRRRLTELRRRLEW',\n",
    "                 '375-QatF' : 'QELKRIEQEIAAIEQEIARAEQKLKAQESDPRKKGLQAEREKLLEKLAELRKERERLSRLEEELRRRLTELRRRLEW',\n",
    "                 '375-QatF-cdel' : 'QELKRIEQEIAAIEQEIARAEQKLKAQESDPRKKGLQAEREKLLEKLAELRKERERLSRLEEELRRRLTE',\n",
    "                 '375-ad-to-A' : 'EEAKRAEEEAAAAEREAARAEEKAKAQESDPRKKGLQAEAEKALEKAAEARKEAERASRLEEELRRRLTELRRRLE',\n",
    "                 '375-ad-to-A-cdel' : 'EEAKRAEEEAAAAEREAARAEEKAKAQESDPRKKGLQAEAEKALEKAAEARKEAERASRLEEELRRRLTE', \n",
    "                 '375-cdel' : 'EELKRIEEEIAAIEREIARAEEKLKAQESDPRKKGLQAEREKLLEKLAELRKERERLSRLEEELRRRLTE', \n",
    "                 '375-cdel-GA' : 'GALKRIEEEIAAIEREIARAEEKLKAQESDPRKKGLQAEREKLLEKLAELRKERERLSRLEEELRRRLTE',\n",
    "                 '375-G53Q' : 'EELKRIEEEIAAIEREIARAEEKLKAQESDPRKKQLQAEREKLLEKLAELRKERERLSRLEEELRRRLTELRRRLE', \n",
    "                 '375-G53Q-GA' : 'GALKRIEEEIAAIEREIARAEEKLKAQESDPRKKQLQAEREKLLEKLAELRKERERLSRLEEELRRRLTELRRRLE', \n",
    "                 '375-G35Q-cdel' : 'EELKRIEEEIAAIEREIARAEEKLKAQESDPRKKQLQAEREKLLEKLAELRKERERLSRLEEELRRRLTE', \n",
    "                 '375-E14Q' : 'EELKRIEEEIAAIQREIARAEEKLKAQESDPRKKGLQAEREKLLEKLAELRKERERLSRLEEELRRRLTELRRRLE', \n",
    "                 '375-E14Q-GA' : 'GALKRIEEEIAAIQREIARAEEKLKAQESDPRKKGLQAEREKLLEKLAELRKERERLSRLEEELRRRLTELRRRLE',\n",
    "                 '375-E14Q-cdel' : 'EELKRIEEEIAAIQREIARAEEKLKAQESDPRKKGLQAEREKLLEKLAELRKERERLSRLEEELRRRLTE', \n",
    "                 '375-E14Q-G35Q' : 'EELKRIEEEIAAIQREIARAEEKLKAQESDPRKKQLQAEREKLLEKLAELRKERERLSRLEEELRRRLTELRRRLE',\n",
    "                 '375-E14Q-G35Q-cdel' : 'EELKRIEEEIAAIQREIARAEEKLKAQESDPRKKQLQAEREKLLEKLAELRKERERLSRLEEELRRRLTE',\n",
    "                 '375-G35A' : 'EELKRIEEEIAAIEREIARAEEKLKAQESDPRKKALQAEREKLLEKLAELRKERERLSRLEEELRRRLTELRRRLE', \n",
    "                 '375-G35A-GA' : 'GALKRIEEEIAAIEREIARAEEKLKAQESDPRKKALQAEREKLLEKLAELRKERERLSRLEEELRRRLTELRRRLE',\n",
    "                 '375-G35A-cdel' : 'EELKRIEEEIAAIEREIARAEEKLKAQESDPRKKALQAEREKLLEKLAELRKERERLSRLEEELRRRLTE', \n",
    "                 '375-L39P' : 'EELKRIEEEIAAIEREIARAEEKLKAQESDPRKKGPQAEREKLLEKLAELRKERERLSRLEEELRRRLTELRRRLE',\n",
    "                 '375-L39P-GA' : 'GALKRIEEEIAAIEREIARAEEKLKAQESDPRKKGPQAEREKLLEKLAELRKERERLSRLEEELRRRLTELRRRLE',\n",
    "                 '375-L39P-cdel' : 'EELKRIEEEIAAIEREIARAEEKLKAQESDPRKKGPQAEREKLLEKLAELRKERERLSRLEEELRRRLTE',\n",
    "                 '375-L36K' : 'EELKRIEEEIAAIEREIARAEEKLKAQESDPRKKGKQAEREKLLEKLAELRKERERLSRLEEELRRRLTELRRRLE',\n",
    "                 '375-L36K-GA' : 'GALKRIEEEIAAIEREIARAEEKLKAQESDPRKKGKQAEREKLLEKLAELRKERERLSRLEEELRRRLTELRRRLE',\n",
    "                 '375-L36K-cdel' : 'EELKRIEEEIAAIEREIARAEEKLKAQESDPRKKGKQAEREKLLEKLAELRKERERLSRLEEELRRRLTE',\n",
    "                 '375-L36Q' : 'EELKRIEEEIAAIEREIARAEEKLKAQESDPRKKGQQAEREKLLEKLAELRKERERLSRLEEELRRRLTELRRRLE',\n",
    "                 '375-L36Q-GA' : 'GALKRIEEEIAAIEREIARAEEKLKAQESDPRKKGQQAEREKLLEKLAELRKERERLSRLEEELRRRLTELRRRLE',\n",
    "                 '375-L36Q-cdel' : 'EELKRIEEEIAAIEREIARAEEKLKAQESDPRKKGQQAEREKLLEKLAELRKERERLSRLEEELRRRLTE',\n",
    "                 '375-ALFA-LtoA' : 'EELKRIEEEIAAIEREIARAEEKLKAQESDPRKKGLQAEREKLLEKLAELRKERERLSRAEEEARRRATELRRRLE',\n",
    "                 '375-ALFA-LtoA-cdel' : 'EELKRIEEEIAAIEREIARAEEKLKAQESDPRKKGLQAEREKLLEKLAELRKERERLSRAEEEARRRATE',\n",
    "                 'bm01-alfa-t6-wt' : 'SRLARRRAALKQRIAALKQRRAALKWQIQSDPRKKQLEQELAALDQEIAAAEQELAALDSRLEEELRRRLTE',\n",
    "                 'bm01-alfa-t6-L1toA' : 'SRLARRRAALKQRIAALKQRRAALKWQIQSDPRKKQLEQELAALDQEIAAAEQELAALDSRAEEELRRRLTE',\n",
    "                 'bm01-alfa-t6-L2toA' : 'SRLARRRAALKQRIAALKQRRAALKWQIQSDPRKKQLEQELAALDQEIAAAEQELAALDSRLEEEARRRLTE',\n",
    "                 'bm01-alfa-t6-L3toA' : 'SRLARRRAALKQRIAALKQRRAALKWQIQSDPRKKQLEQELAALDQEIAAAEQELAALDSRLEEELRRRATE',\n",
    "                 'bm01-alfa-t6-LtoA' : 'SRLARRRAALKQRIAALKQRRAALKWQIQSDPRKKQLEQELAALDQEIAAAEQELAALDSRAEEEARRRATE'}\n",
    "\n",
    "#make df with columns 'Name and 'sequence' from dict\n",
    "bespoke_ctrls_df = pd.DataFrame.from_dict(bespoke_ctrls_dict, orient='index', columns=['Sequence']).reset_index().rename(columns={'index': 'Name'})\n",
    "bespoke_ctrls_df.shape\n",
    "\n",
    "bespoke_ctrls_df.to_csv(f'{outdir}/ctrl_seqs_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "9c93827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#control seq functions\n",
    "\n",
    "####Heptad a and d to Ala####\n",
    "def heptad_to_upper(input_string, split_char = 'r '):\n",
    "    split_1 = input_string.split(split_char)[0]\n",
    "    split_2 = input_string.split(split_char)[1]\n",
    "    split_2 = split_2.upper()\n",
    "    \n",
    "    new_string = split_1+split_char+split_2\n",
    "\n",
    "    return new_string\n",
    "\n",
    "\n",
    "def heptad_a_d_to_ala(reg_string, seq_string):\n",
    "\n",
    "    og_seq = re.split(r'\\s+', seq_string)[1]\n",
    "    \n",
    "    for index, char in enumerate(reg_string):\n",
    "        if char.isupper():\n",
    "            if char in ['A', 'D']:\n",
    "                seq_string = seq_string[:index] + 'A' + seq_string[index+1:]\n",
    "            else:\n",
    "                continue\n",
    "    \n",
    "    new_seq = re.split(r'\\s+', seq_string)[1]\n",
    "\n",
    "    return og_seq, new_seq\n",
    "\n",
    "\n",
    "def a_d_to_ala(input_df, state='ssd'):\n",
    "\n",
    "    new_seqs_dict = {}\n",
    "\n",
    "    if state == 'ssd':\n",
    "        h1_reg_colname = 'h1_reg'\n",
    "        h2_reg_colname = 'h2_reg'\n",
    "\n",
    "        h1_seq_colname = 'h1_seq'\n",
    "        h2_seq_colname = 'h2_seq'\n",
    "    elif state == 'msd':\n",
    "        h1_reg_colname = 'h1_reg_min2'\n",
    "        h2_reg_colname = 'h2_reg_min2'\n",
    "\n",
    "        h1_seq_colname = 'h1_seq_min2'\n",
    "        h2_seq_colname = 'h2_seq_min2'\n",
    "\n",
    "    for index, row in input_df.iterrows():\n",
    "\n",
    "        h1_reg = row[h1_reg_colname]\n",
    "        new_h1_reg = heptad_to_upper(h1_reg)\n",
    "\n",
    "        h1_seq = row[h1_seq_colname]\n",
    "\n",
    "        h1_og, h1_new = heptad_a_d_to_ala(new_h1_reg, h1_seq)\n",
    "\n",
    "        h2_reg = row[h2_reg_colname]\n",
    "        new_h2_reg = heptad_to_upper(h2_reg)\n",
    "\n",
    "        h2_seq = row[h2_seq_colname]\n",
    "\n",
    "        h2_og, h2_new = heptad_a_d_to_ala(new_h2_reg, h2_seq)\n",
    "\n",
    "        #replace with ala seq in sequence\n",
    "        sequence = row['final_sequence_for_ad']\n",
    "        new_sequence = sequence.replace(h1_og, h1_new)\n",
    "        new_sequence = new_sequence.replace(h2_og, h2_new)\n",
    "\n",
    "        new_seqs_dict[sequence] = new_sequence\n",
    "\n",
    "    new_df = input_df.copy()\n",
    "    new_df['a_d_to_ala_sequence'] = new_df['final_sequence_for_ad'].map(new_seqs_dict)\n",
    "\n",
    "    return new_df\n",
    "\n",
    "####\n",
    "\n",
    "####SCRAMBLE CONTROLS####\n",
    "def full_scrambler(sequence_list):\n",
    "    '''function for full scrambles use random.sample\n",
    "    Takes a list of original design sequences\n",
    "    Outputs a dictionary with original seq and fully scrambled seq as key:value pair'''\n",
    "\n",
    "    full_scramble_dict = {}\n",
    "    for seq in sequence_list:\n",
    "        residues = list(seq)\n",
    "        sc_residues = random.sample(residues, k=len(residues))\n",
    "        sc_seq = ''.join(sc_residues)\n",
    "        full_scramble_dict[seq] = sc_seq\n",
    "    return full_scramble_dict\n",
    "\n",
    "def patterned_scrambler(sequence_list):\n",
    "    '''Function for creating patterned scrambled designs\n",
    "    In which hydrophobic or polar residues are shuffled to different positions with the same h or p character\n",
    "    prolines and glycines are kept in original positions\n",
    "    based on criteria described in in Rocklin, et al. 2017\n",
    "    Takes a list of original design sequences\n",
    "    Outputs a data frame with the original sequence, pattern of H/P/Pro/Gly, and the patterned scramble sequence'''\n",
    "\n",
    "    patterned_scramble_dict = {}\n",
    "    #Rocklin term these polar if they occur in a helix: D, E, H, K, N, Q, R, S, T, or Y\n",
    "    #A, F, I, L, M, V, W, and Y used to count number of hydrophobic aa\n",
    "    #I just used hydrophobic and polar definitions from default resfile categories\n",
    "    hydrophobics_list = ['A', 'F', 'I', 'L', 'M', 'V', 'W', 'Y']\n",
    "    polar_list = ['D', 'E', 'H', 'K', 'N', 'Q', 'R', 'S', 'T']\n",
    "    seq_pattern_dict = {}\n",
    "\n",
    "    for seq in sequence_list:\n",
    "        residues = list(seq)\n",
    "        patterned_res = []\n",
    "        hydrophobic_residues = []\n",
    "        polar_residues = []\n",
    "        patterned_scramble_res = []\n",
    "        for res in residues:\n",
    "            if res == 'P':\n",
    "                patterned_res.append('Pro')\n",
    "\n",
    "            elif res == 'G':\n",
    "                patterned_res.append('G')\n",
    "\n",
    "            elif res in hydrophobics_list:\n",
    "                patterned_res.append('H')\n",
    "                hydrophobic_residues.append(res)\n",
    "\n",
    "            elif res in polar_list:\n",
    "                patterned_res.append('P')\n",
    "                polar_residues.append(res)\n",
    "\n",
    "            else:\n",
    "                print('Cys found!')\n",
    "\n",
    "        seq_pattern = ''.join(patterned_res)\n",
    "        seq_pattern_dict[seq] = seq_pattern\n",
    "\n",
    "        for res in patterned_res:\n",
    "\n",
    "            if res == 'Pro':\n",
    "                patterned_scramble_res.append('P')\n",
    "            elif res == 'G':\n",
    "                patterned_scramble_res.append('G')\n",
    "            elif res == 'H':\n",
    "                l = random.randint(0, len(hydrophobic_residues)-1)\n",
    "                r = hydrophobic_residues.pop(l)\n",
    "                patterned_scramble_res.append(r)\n",
    "            elif res == 'P':\n",
    "                l = random.randint(0, len(polar_residues)-1)\n",
    "                r = polar_residues.pop(l)\n",
    "                patterned_scramble_res.append(r)\n",
    "        pattern_scramble_seq = ''.join(patterned_scramble_res)\n",
    "        patterned_scramble_dict[seq] = pattern_scramble_seq\n",
    "\n",
    "    df_name_pattern = pd.DataFrame.from_dict(seq_pattern_dict, orient='index', columns=['Seq HP pattern'])\n",
    "    df_name_pattern.index.name = 'Insert protein sequence'\n",
    "    df_name_pattern.reset_index(inplace=True)\n",
    "\n",
    "    df_name_pattern_sc = pd.DataFrame.from_dict(patterned_scramble_dict, orient='index', columns=['patterned_scramble_sequence'])\n",
    "    df_name_pattern_sc.index.name = 'Insert protein sequence'\n",
    "    df_name_pattern_sc.reset_index(inplace=True)\n",
    "\n",
    "    df = pd.merge(df_name_pattern, df_name_pattern_sc, on='Insert protein sequence')\n",
    "\n",
    "    return df\n",
    "\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "0761311d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scrambles: 384\n"
     ]
    }
   ],
   "source": [
    "#randomly sample 37 from each set to create scrambles\n",
    "\n",
    "scramble_seq_dfs = []\n",
    "\n",
    "#for ssd select min2 only so alfa tag not mutated\n",
    "r2_ssd_mpnn_scrambles_df = r2_ssd_df.query(\"seq_method == 'mpnn' & min_condition == 'min2'\").sample(n=32, axis=0, random_state=42)\n",
    "r2_ssd_f2s_scrambles_df = r2_ssd_df.query(\"seq_method == 'f2s' & min_condition == 'min2'\").sample(n=32, axis=0, random_state=42)\n",
    "ssd_scrambles_df = pd.concat([r2_ssd_mpnn_scrambles_df, r2_ssd_f2s_scrambles_df], ignore_index=True)\n",
    "\n",
    "#make second final_sequence column that will match the h1 and h2 helices without N-term GA\n",
    "ssd_scrambles_df['final_sequence_for_ad'] = ssd_scrambles_df['sequence'].str.split('SRLEEELRRRLTE').str[0] + 'SRLEEELRRRLTE'\n",
    "\n",
    "#make ssd ad to ala scrambles\n",
    "ssd_scrambles_df = a_d_to_ala(ssd_scrambles_df, state='ssd')\n",
    "\n",
    "#replace N-term residues with 'GA'\n",
    "ssd_scrambles_df['a_d_to_ala_sequence'] = 'GA' + ssd_scrambles_df['a_d_to_ala_sequence'].str[2:]\n",
    "\n",
    "#update name\n",
    "ssd_scrambles_df['shortname'] = ssd_scrambles_df['shortname'] + '_ad_scramble'\n",
    "\n",
    "ssd_scrambles_df_subset = ssd_scrambles_df[['shortname', 'a_d_to_ala_sequence']]\n",
    "ssd_scrambles_df_subset = ssd_scrambles_df_subset.rename(columns={'shortname':'Name', 'a_d_to_ala_sequence': 'Sequence'})\n",
    "scramble_seq_dfs.append(ssd_scrambles_df_subset)\n",
    "\n",
    "r2_msd_mpnn_scrambles_df = r2_msd_all_df.query(\"seq_design_method_min0 == 'MPNN'\").sample(n=32, axis=0, random_state=42)\n",
    "r2_msd_f2s_scrambles_df = r2_msd_all_df.query(\"seq_design_method_min0 == 'f2s_os'\").sample(n=32, axis=0, random_state=42)\n",
    "msd_scrambles_df = pd.concat([r2_msd_mpnn_scrambles_df, r2_msd_f2s_scrambles_df], ignore_index=True)\n",
    "\n",
    "#make second final_sequence column that will match the h1 and h2 helices without N-term GA\n",
    "msd_scrambles_df['final_sequence_for_ad'] = msd_scrambles_df['sequence'].str.split('SRLEEELRRRLTE').str[0] + 'SRLEEELRRRLTE'\n",
    "\n",
    "#make msd ad to ala scrambles\n",
    "msd_scrambles_df = a_d_to_ala(msd_scrambles_df, state='msd')\n",
    "\n",
    "#replace N-term residues with 'GA'\n",
    "msd_scrambles_df['a_d_to_ala_sequence'] = 'GA' + msd_scrambles_df['a_d_to_ala_sequence'].str[2:]\n",
    "\n",
    "#update name\n",
    "msd_scrambles_df['shortname'] = msd_scrambles_df['shortname'] + '_ad_scramble'\n",
    "\n",
    "msd_scrambles_df_subset = msd_scrambles_df[['shortname', 'a_d_to_ala_sequence']]\n",
    "msd_scrambles_df_subset = msd_scrambles_df_subset.rename(columns={'shortname':'Name', 'a_d_to_ala_sequence': 'Sequence'})\n",
    "scramble_seq_dfs.append(msd_scrambles_df_subset)\n",
    "\n",
    "#combine\n",
    "scramble_dfs_to_concat = [ssd_scrambles_df, msd_scrambles_df]\n",
    "scrambles_df = pd.concat(scramble_dfs_to_concat, ignore_index=True)\n",
    "\n",
    "#for full and patterned scrambles, delete the alfa tag first, scramble, then add it back\n",
    "scrambles_df['duplicated_sequence'] = scrambles_df['final_sequence'].str.split('SRLEEELRRRLTE').str[0]\n",
    "\n",
    "#full scrambles\n",
    "full_scramble_dict = full_scrambler(scrambles_df['duplicated_sequence'].tolist())\n",
    "scrambles_df['full_scramble_sequence'] = scrambles_df['duplicated_sequence'].map(full_scramble_dict)\n",
    "scrambles_df['full_scramble_sequence'] = scrambles_df['full_scramble_sequence'] + 'SRLEEELRRRLTE'\n",
    "\n",
    "#update name\n",
    "scrambles_df['shortname_full'] = scrambles_df['shortname'] + '_full_scramble'\n",
    "full_scrambles_df_subset = scrambles_df[['shortname_full', 'full_scramble_sequence']]\n",
    "full_scrambles_df_subset = full_scrambles_df_subset.rename(columns={'shortname_full': 'Name', 'full_scramble_sequence': 'Sequence'})\n",
    "scramble_seq_dfs.append(full_scrambles_df_subset)\n",
    "\n",
    "#patterned scrambles\n",
    "patterned_scramble_df = patterned_scrambler(scrambles_df['duplicated_sequence'].tolist())\n",
    "scrambles_df = pd.merge(scrambles_df, patterned_scramble_df, left_on='duplicated_sequence', right_on='Insert protein sequence', how='left')\n",
    "scrambles_df['patterned_scramble_sequence'] = scrambles_df['patterned_scramble_sequence'] + 'SRLEEELRRRLTE'\n",
    "\n",
    "#update name\n",
    "scrambles_df['shortname_pat'] = scrambles_df['shortname'] + '_patterned_scramble'\n",
    "pat_scrambles_df_subset = scrambles_df[['shortname_pat', 'patterned_scramble_sequence']]\n",
    "pat_scrambles_df_subset = pat_scrambles_df_subset.rename(columns={'shortname_pat': 'Name', 'patterned_scramble_sequence': 'Sequence'})\n",
    "scramble_seq_dfs.append(pat_scrambles_df_subset)\n",
    "\n",
    "all_scrambles_df = pd.concat(scramble_seq_dfs, ignore_index=True)\n",
    "print(f'Number of scrambles: {all_scrambles_df.shape[0]}')\n",
    "\n",
    "all_scrambles_df.to_csv(f'{outdir}/scramble_seqs_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "fcdb9e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of sequences: 1813\n",
      "1813\n",
      "1813\n"
     ]
    }
   ],
   "source": [
    "#combine all dfs\n",
    "r2_ssd_short_df = r2_ssd_short_df.rename(columns={'shortname': 'Name', 'final_sequence': 'Sequence'})\n",
    "r2_msd_all_short_df = r2_msd_all_short_df.rename(columns={'shortname': 'Name', 'final_sequence': 'Sequence'})\n",
    "r2_msd_one_state_short_df = r2_msd_one_state_short_df.rename(columns={'shortname': 'Name', 'final_sequence': 'Sequence'})\n",
    "\n",
    "final_dfs_to_concat = [r2_ssd_short_df, r2_msd_all_short_df, r2_msd_one_state_short_df, all_scrambles_df, bespoke_ctrls_df]\n",
    "final_df = pd.concat(final_dfs_to_concat, ignore_index=True)\n",
    "print(f'Final number of sequences: {final_df.shape[0]}')\n",
    "print(final_df.Name.nunique())\n",
    "print(final_df.Sequence.nunique())\n",
    "\n",
    "final_df.to_csv(f'{outdir}/r2_hs_all_protein_seqs_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "a73dc3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 3)\n"
     ]
    }
   ],
   "source": [
    "#load in r1-hs control sequences (nucleotide)\n",
    "r1_hs_nt_seqs_path = '/Users/stephaniecrilly/Library/CloudStorage/Box-Box/kortemmelab/home/scrilly/helix_sliding/20231212_final_analysis_r1_order/20231221_final_order/20231222_helix_ssd_r1_opt_seqs.csv'\n",
    "r1_hs_nt_seqs_df = pd.read_csv(r1_hs_nt_seqs_path)\n",
    "\n",
    "#filter out bm01 seqs\n",
    "r1_hs_nt_seqs_df = r1_hs_nt_seqs_df.query(\"not Name.str.startswith('bm01')\", engine='python').copy()\n",
    "\n",
    "#make truncated sequence\n",
    "leading_bases = 'agcggaggcggagggtcggcttcgcatatg'\n",
    "trailing_bases = 'ctcgagggtggaggttccgaacaacagctt'\n",
    "\n",
    "r1_hs_nt_52 = r1_hs_nt_seqs_df.query(\"Name.str.contains('52')\", engine='python').copy()\n",
    "r1_hs_nt_52['Sequence'] = r1_hs_nt_52['Sequence'].str.split(leading_bases).str[1]\n",
    "r1_hs_nt_52['Sequence'] = r1_hs_nt_52['Sequence'].str.split(trailing_bases).str[0]\n",
    "r1_hs_nt_52['Sequence'] = r1_hs_nt_52['Sequence'].str[:-18]\n",
    "r1_hs_nt_52['Sequence'] = leading_bases + r1_hs_nt_52['Sequence'] + trailing_bases\n",
    "r1_hs_nt_52['Name'] = r1_hs_nt_52['Name'] + '_r1_trunc'\n",
    "\n",
    "r1_hs_nt_53 = r1_hs_nt_seqs_df.query(\"Name.str.contains('53')\", engine='python').copy()\n",
    "r1_hs_nt_53['Sequence'] = r1_hs_nt_53['Sequence'].str.split(leading_bases).str[1]\n",
    "r1_hs_nt_53['Sequence'] = r1_hs_nt_53['Sequence'].str.split(trailing_bases).str[0]\n",
    "r1_hs_nt_53['Sequence'] = r1_hs_nt_53['Sequence'].str[:-15]\n",
    "r1_hs_nt_53['Sequence'] = leading_bases + r1_hs_nt_53['Sequence'] + trailing_bases\n",
    "r1_hs_nt_53['Name'] = r1_hs_nt_53['Name'] + '_r1_trunc'\n",
    "\n",
    "r1_hs_nt_seqs_df['Name'] = r1_hs_nt_seqs_df['Name'] + '_r1'\n",
    "\n",
    "r1_hs_ctrl_seqs_df = pd.concat([r1_hs_nt_seqs_df, r1_hs_nt_52, r1_hs_nt_53], ignore_index=True)\n",
    "print(r1_hs_ctrl_seqs_df.shape)   \n",
    "\n",
    "r1_hs_ctrl_seqs_df.to_csv(f'{outdir}/r2_hs_r1_ctrl_nt_seqs_final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plotting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
