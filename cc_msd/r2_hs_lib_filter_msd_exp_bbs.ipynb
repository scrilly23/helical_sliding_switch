{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "####USER DEFINED VARIABLES####\n",
    "r2_indir = '/Users/stephaniecrilly/Library/CloudStorage/Box-Box/kortemmelab/home/scrilly/helix_sliding/20250604_r2_hs_lib/metric_files/msd_exp_bbs/msd_r2'\n",
    "r3_indir = '/Users/stephaniecrilly/Library/CloudStorage/Box-Box/kortemmelab/home/scrilly/helix_sliding/20250604_r2_hs_lib/metric_files/msd_exp_bbs/msd_r3'\n",
    "outdir = '/Users/stephaniecrilly/Library/CloudStorage/Box-Box/kortemmelab/home/scrilly/helix_sliding/20250604_r2_hs_lib/metric_files/msd_exp_bbs'\n",
    "\n",
    "seq_design_condition = 'MSD'\n",
    "\n",
    "#filter cutoffs\n",
    "strictest_rmsd_cutoff = 0.5\n",
    "strict_rmsd_cutoff = 1.0\n",
    "lenient_rmsd_cutoff = 1.5\n",
    "plddt_cutoff = 80\n",
    "pae_cutoff = 5\n",
    "min0_motif_res_in_heptad = 7\n",
    "min2_motif_res_in_heptad = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01\n",
      "seqs_df shape: 1000\n",
      "af2_df shape: 5000\n",
      "socket_fil_df shape: 5000\n",
      "socket_df shape: 4787\n",
      "03\n",
      "seqs_df shape: 1000\n",
      "af2_df shape: 5000\n",
      "socket_fil_df shape: 5000\n",
      "socket_df shape: 4585\n",
      "05\n",
      "seqs_df shape: 1000\n",
      "af2_df shape: 5000\n",
      "socket_fil_df shape: 5000\n",
      "socket_df shape: 4105\n"
     ]
    }
   ],
   "source": [
    "#MPNN for af2 backbones\n",
    "input_bb_type = 'af2_bm01_loop'\n",
    "seq_design_method = 'MPNN'\n",
    "\n",
    "temps = ['01', '03', '05']\n",
    "\n",
    "#make mpnn_log.txt file in outdir\n",
    "mpnn_log_file = os.path.join(outdir, f'{seq_design_condition}_mpnn_log.txt')\n",
    "with open(mpnn_log_file, 'w') as log_file:\n",
    "    log_file.write(f'Processing MPNN metrics for {seq_design_condition}, {input_bb_type} backbones condition\\n\\n')\n",
    "    log_file.write(f'Input directory: {r2_indir}\\n\\n')\n",
    "    log_file.write(f'Output directory: {outdir}\\n\\n')\n",
    "\n",
    "full_dfs_to_concat = []\n",
    "\n",
    "for temp in temps:\n",
    "\n",
    "    #load corresponding dataframes\n",
    "    af2_df = pd.read_csv(os.path.join(r2_indir, f'af2_metrics_msd_r2_t{temp}.csv'))\n",
    "    seqs_df = pd.read_csv(os.path.join(r2_indir, f'13632_ALFA_52_07144_ALFA_52_bm01_loop_t_{temp}_mpnn_ssd_new_seqs.csv'))\n",
    "    socket_fil_df = pd.read_csv(os.path.join(r2_indir, f'MSD_13632_07144_socket_filtered_t_{temp}.csv'))\n",
    "\n",
    "    thread_position = '52'\n",
    "    loop = 'bm01'\n",
    "    min0_bb_id = '13632'\n",
    "    min2_bb_id = '07144'\n",
    "\n",
    "    #add additional info\n",
    "    af2_df['state_design'] = seq_design_condition\n",
    "    af2_df['thread_position'] = thread_position\n",
    "    af2_df['loop'] = loop\n",
    "    af2_df['input_bb_type'] = input_bb_type\n",
    "    af2_df['seq_design_method'] = seq_design_method\n",
    "    af2_df['min0_bb_id'] = min0_bb_id\n",
    "    af2_df['min2_bb_id'] = min2_bb_id\n",
    "    af2_df[['seq_id', 'af2_model_info']] = af2_df['design_id'].str.split('_unrelaxed_', regex=True, expand=True)\n",
    "\n",
    "    #print out number of seqs\n",
    "    print(temp)\n",
    "    print(f'seqs_df shape: {seqs_df.shape[0]}') #should be 1/5 of af2_df\n",
    "    print(f'af2_df shape: {af2_df.shape[0]}')\n",
    "    print(f'socket_fil_df shape: {socket_fil_df.shape[0]}') #should be same as af2_df, unless some sockets didn't run\n",
    "\n",
    "    #merge af2 and seqs df\n",
    "    af2_seqs_df = pd.merge(af2_df, seqs_df, how='inner', on='seq_id')\n",
    "\n",
    "    #merge with socket filtered df\n",
    "    full_df = pd.merge(af2_seqs_df, socket_fil_df, how='inner', on='design_id')\n",
    "    full_df = full_df.loc[:, ~full_df.columns.str.contains('^Unnamed')]\n",
    "    full_dfs_to_concat.append(full_df)\n",
    "\n",
    "    #merge with all socket metrics for structure with cc\n",
    "    socket_df = pd.read_csv(os.path.join(r2_indir, f'MSD_13632_07144_all_socket_outputs_t_{temp}.csv'))\n",
    "    socket_df = socket_df.loc[:, ~socket_df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "    #merge with full_df\n",
    "    cc_design_metrics_df = full_df.merge(socket_df, on=['design_id', 'socket_call', 'h1_seq', 'h1_reg', 'h2_seq', 'h2_reg', 'h1_non_canon_num_res', 'h2_non_canon_num_res'], how='right')\n",
    "    print(f'socket_df shape: {socket_df.shape[0]}') #should reflect number of pdbs detected as cc\n",
    "    cc_design_metrics_df.to_csv(f'{outdir}/{seq_design_condition}_{seq_design_method}_{thread_position}_{loop}_{input_bb_type}_{temp}_all_metrics.csv')\n",
    "\n",
    "    with open(mpnn_log_file, 'a') as log_file:\n",
    "        log_file.write(f'{temp} total seqs: {seqs_df.shape[0]}\\n')\n",
    "        log_file.write(f'{temp} af2 structures: {af2_df.shape[0]}\\n')\n",
    "        log_file.write(f'{temp} socket filtered structures: {socket_fil_df.shape[0]}\\n')\n",
    "        log_file.write(f'{temp} socket metrics: {socket_df.shape[0]} total\\n\\n')\n",
    "\n",
    "#save master mpnn df\n",
    "full_df = pd.concat(full_dfs_to_concat)\n",
    "full_df.to_csv(f'{outdir}/{seq_design_condition}_{seq_design_method}_{input_bb_type}_{temp}_compiled_metrics.csv')        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01\n",
      "seqs_df shape: 1000\n",
      "af2_df shape: 5000\n",
      "socket_fil_df shape: 5000\n",
      "socket_df shape: 3864\n",
      "03\n",
      "seqs_df shape: 1000\n",
      "af2_df shape: 4940\n",
      "socket_fil_df shape: 4940\n",
      "socket_df shape: 3929\n",
      "05\n",
      "seqs_df shape: 1000\n",
      "af2_df shape: 4970\n",
      "socket_fil_df shape: 4970\n",
      "socket_df shape: 3834\n"
     ]
    }
   ],
   "source": [
    "#MPNN for af2 backbones\n",
    "input_bb_type = 'af2_bm01_loop_redesigned'\n",
    "seq_design_method = 'MPNN'\n",
    "\n",
    "temps = ['01', '03', '05']\n",
    "\n",
    "#make mpnn_log.txt file in outdir\n",
    "mpnn_log_file = os.path.join(outdir, f'{seq_design_condition}_mpnn_log.txt')\n",
    "with open(mpnn_log_file, 'a') as log_file:\n",
    "    log_file.write(f'Processing MPNN metrics for {seq_design_condition}, {input_bb_type} backbones condition\\n\\n')\n",
    "    log_file.write(f'Input directory: {r3_indir}\\n\\n')\n",
    "    log_file.write(f'Output directory: {outdir}\\n\\n')\n",
    "\n",
    "full_dfs_to_concat = []\n",
    "\n",
    "for temp in temps:\n",
    "\n",
    "    #load corresponding dataframes\n",
    "    af2_df = pd.read_csv(os.path.join(r3_indir, f'af2_metrics_t_{temp}.csv'))\n",
    "    seqs_df = pd.read_csv(os.path.join(r3_indir, f'13632_ALFA_52_07144_ALFA_52_bm01_loop_redesigned_t_{temp}_mpnn_ssd_new_seqs.csv'))\n",
    "    socket_fil_df = pd.read_csv(os.path.join(r3_indir, f'MSD_13632_07144_bm01_loop_redesigned_t_{temp}_socket_filtered.csv'))\n",
    "\n",
    "    thread_position = '52'\n",
    "    loop = 'bm01'\n",
    "    min0_bb_id = '13632'\n",
    "    min2_bb_id = '07144'\n",
    "\n",
    "    #add additional info\n",
    "    af2_df['state_design'] = seq_design_condition\n",
    "    af2_df['thread_position'] = thread_position\n",
    "    af2_df['loop'] = loop\n",
    "    af2_df['input_bb_type'] = input_bb_type\n",
    "    af2_df['seq_design_method'] = seq_design_method\n",
    "    af2_df['min0_bb_id'] = min0_bb_id\n",
    "    af2_df['min2_bb_id'] = min2_bb_id\n",
    "    af2_df[['seq_id', 'af2_model_info']] = af2_df['design_id'].str.split('_unrelaxed_', regex=True, expand=True)\n",
    "\n",
    "    #print out number of seqs\n",
    "    print(temp)\n",
    "    print(f'seqs_df shape: {seqs_df.shape[0]}') #should be 1/5 of af2_df\n",
    "    print(f'af2_df shape: {af2_df.shape[0]}')\n",
    "    print(f'socket_fil_df shape: {socket_fil_df.shape[0]}') #should be same as af2_df, unless some sockets didn't run\n",
    "\n",
    "    #merge af2 and seqs df\n",
    "    af2_seqs_df = pd.merge(af2_df, seqs_df, how='inner', on='seq_id')\n",
    "\n",
    "    #merge with socket filtered df\n",
    "    full_df = pd.merge(af2_seqs_df, socket_fil_df, how='inner', on='design_id')\n",
    "    full_df = full_df.loc[:, ~full_df.columns.str.contains('^Unnamed')]\n",
    "    full_dfs_to_concat.append(full_df)\n",
    "\n",
    "    #merge with all socket metrics for structure with cc\n",
    "    socket_df = pd.read_csv(os.path.join(r3_indir, f'MSD_13632_07144_bm01_loop_redesigned_t_{temp}_all_socket_outputs.csv'))\n",
    "    socket_df = socket_df.loc[:, ~socket_df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "    #merge with full_df\n",
    "    cc_design_metrics_df = full_df.merge(socket_df, on=['design_id', 'socket_call', 'h1_seq', 'h1_reg', 'h2_seq', 'h2_reg', 'h1_non_canon_num_res', 'h2_non_canon_num_res'], how='right')\n",
    "    print(f'socket_df shape: {socket_df.shape[0]}') #should reflect number of pdbs detected as cc\n",
    "    cc_design_metrics_df.to_csv(f'{outdir}/{seq_design_condition}_{seq_design_method}_{thread_position}_{loop}_{input_bb_type}_{temp}_all_metrics.csv')\n",
    "\n",
    "    with open(mpnn_log_file, 'a') as log_file:\n",
    "        log_file.write(f'{temp} total seqs: {seqs_df.shape[0]}\\n')\n",
    "        log_file.write(f'{temp} af2 structures: {af2_df.shape[0]}\\n')\n",
    "        log_file.write(f'{temp} socket filtered structures: {socket_fil_df.shape[0]}\\n')\n",
    "        log_file.write(f'{temp} socket metrics: {socket_df.shape[0]} total\\n\\n')\n",
    "\n",
    "#save master mpnn df\n",
    "full_df = pd.concat(full_dfs_to_concat)\n",
    "full_df.to_csv(f'{outdir}/{seq_design_condition}_{seq_design_method}_{input_bb_type}_{temp}_compiled_metrics.csv')        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: MSD_MPNN_52_bm01_af2_bm01_loop_01_all_metrics.csv\n",
      "(4787, 44)\n",
      "991\n",
      "plddt filtered: 989\n",
      "pae filtered: 956\n",
      "rmsd filtered (min0 only): 888\n",
      "rmsd filtered (min2 only): 80\n",
      "rmsd filtered: 15\n",
      "min0 only: 873\n",
      "min2 only: 65\n",
      "Processing file: MSD_MPNN_52_bm01_af2_bm01_loop_redesigned_01_all_metrics.csv\n",
      "(3864, 44)\n",
      "903\n",
      "plddt filtered: 886\n",
      "pae filtered: 674\n",
      "rmsd filtered (min0 only): 587\n",
      "rmsd filtered (min2 only): 101\n",
      "rmsd filtered: 17\n",
      "min0 only: 570\n",
      "min2 only: 84\n",
      "Processing file: MSD_MPNN_52_bm01_af2_bm01_loop_05_all_metrics.csv\n",
      "(4105, 44)\n",
      "944\n",
      "plddt filtered: 924\n",
      "pae filtered: 786\n",
      "rmsd filtered (min0 only): 550\n",
      "rmsd filtered (min2 only): 272\n",
      "rmsd filtered: 39\n",
      "min0 only: 511\n",
      "min2 only: 233\n",
      "Processing file: MSD_MPNN_52_bm01_af2_bm01_loop_redesigned_03_all_metrics.csv\n",
      "(3929, 44)\n",
      "912\n",
      "plddt filtered: 899\n",
      "pae filtered: 714\n",
      "rmsd filtered (min0 only): 543\n",
      "rmsd filtered (min2 only): 196\n",
      "rmsd filtered: 28\n",
      "min0 only: 515\n",
      "min2 only: 168\n",
      "Processing file: MSD_MPNN_52_bm01_af2_bm01_loop_03_all_metrics.csv\n",
      "(4585, 44)\n",
      "984\n",
      "plddt filtered: 977\n",
      "pae filtered: 879\n",
      "rmsd filtered (min0 only): 729\n",
      "rmsd filtered (min2 only): 179\n",
      "rmsd filtered: 30\n",
      "min0 only: 699\n",
      "min2 only: 149\n",
      "Processing file: MSD_MPNN_52_bm01_af2_bm01_loop_redesigned_05_all_metrics.csv\n",
      "(3834, 44)\n",
      "906\n",
      "plddt filtered: 889\n",
      "pae filtered: 682\n",
      "rmsd filtered (min0 only): 467\n",
      "rmsd filtered (min2 only): 227\n",
      "rmsd filtered: 24\n",
      "min0 only: 443\n",
      "min2 only: 203\n",
      "(153, 87)\n",
      "153\n"
     ]
    }
   ],
   "source": [
    "passing_designs_to_concat = []\n",
    "min0_passing_designs_to_concat = []\n",
    "min2_passing_designs_to_concat = []\n",
    "\n",
    "for file in os.listdir(outdir):\n",
    "    if file.endswith('all_metrics.csv'):\n",
    "        print(f\"Processing file: {file}\")\n",
    "\n",
    "        # Read in the data\n",
    "        df = pd.read_csv(os.path.join(outdir, file), index_col=0)\n",
    "        print(df.shape)\n",
    "        print(len(df['sequence'].unique()))\n",
    "\n",
    "        #filter for plddt\n",
    "        df = df.query('avg_plddt_no_loop > @plddt_cutoff', engine='python').copy()\n",
    "        print(f\"plddt filtered: {len(df['sequence'].unique())}\")\n",
    "        \n",
    "        #filter for pae\n",
    "        df = df.query('avg_pae_no_loop < @pae_cutoff', engine='python').copy()\n",
    "        print(f\"pae filtered: {len(df['sequence'].unique())}\")\n",
    "\n",
    "        #get prediction with lowest rmsd to each state\n",
    "        lowest_rmsd_min0_df = df.sort_values('min0_all_rmsd_no_loop', ascending=True).drop_duplicates('sequence').sort_index()\n",
    "        lowest_rmsd_min0_df = lowest_rmsd_min0_df.query('min0_all_rmsd_no_loop < @lenient_rmsd_cutoff').copy()\n",
    "        print(f\"rmsd filtered (min0 only): {len(lowest_rmsd_min0_df['sequence'].unique())}\")\n",
    "\n",
    "        lowest_rmsd_min2_df = df.sort_values('min2_all_rmsd_no_loop', ascending=True).drop_duplicates('sequence').sort_index()\n",
    "        lowest_rmsd_min2_df = lowest_rmsd_min2_df.query('min2_all_rmsd_no_loop < @lenient_rmsd_cutoff').copy()\n",
    "        print(f\"rmsd filtered (min2 only): {len(lowest_rmsd_min2_df['sequence'].unique())}\")\n",
    "\n",
    "        intersect_df = pd.merge(lowest_rmsd_min0_df, lowest_rmsd_min2_df, how='inner', on='sequence', suffixes=('_min0', '_min2'))\n",
    "        print(f\"rmsd filtered: {len(intersect_df['sequence'].unique())}\")\n",
    "        passing_designs_to_concat.append(intersect_df)\n",
    "\n",
    "        #get sequences that pass filters for only one state\n",
    "        min0_only_df = lowest_rmsd_min0_df[~lowest_rmsd_min0_df['sequence'].isin(intersect_df['sequence'])]\n",
    "        print(f\"min0 only: {len(min0_only_df['sequence'].unique())}\")\n",
    "        min0_passing_designs_to_concat.append(min0_only_df)\n",
    "\n",
    "        min2_only_df = lowest_rmsd_min2_df[~lowest_rmsd_min2_df['sequence'].isin(intersect_df['sequence'])]\n",
    "        print(f\"min2 only: {len(min2_only_df['sequence'].unique())}\")\n",
    "        min2_passing_designs_to_concat.append(min2_only_df)\n",
    "\n",
    "all_passing_designs_df = pd.concat(passing_designs_to_concat)\n",
    "min0_passing_designs_df = pd.concat(min0_passing_designs_to_concat)\n",
    "min2_passing_designs_df = pd.concat(min2_passing_designs_to_concat)\n",
    "print(all_passing_designs_df.shape)\n",
    "print(len(all_passing_designs_df['sequence'].unique()))\n",
    "all_passing_designs_df.to_csv(f'{outdir}/exp_bbs_msd_designs_passing.csv')\n",
    "min0_passing_designs_df.to_csv(f'{outdir}/exp_bbs_msd_designs_passing_min0_only.csv')\n",
    "min2_passing_designs_df.to_csv(f'{outdir}/exp_bbs_msd_designs_passing_min2_only.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plotting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
